// src/pages/InterviewSessionPage.jsx

import { useState, useEffect, useRef } from 'react';
import { useParams, useNavigate } from 'react-router-dom';
import apiClient from '../api/apiClient';

function InterviewSessionPage() {
  const { id } = useParams();
  const navigate = useNavigate();

  const [interviewSet, setInterviewSet] = useState(null);
  const [questions, setQuestions] = useState([]);
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0);
  const [status, setStatus] = useState('ready');
  const [loading, setLoading] = useState(true);

  const videoRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const recordedChunksRef = useRef([]);
  const streamRef = useRef(null);

  useEffect(() => {
    const fetchInterviewData = async () => {
      try {
        const response = await apiClient.get(`/api/interview-sets/${id}`);
        setInterviewSet(response.data);
        setQuestions(response.data.questions);
      } catch (error) {
        console.error('ë©´ì ‘ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error);
      } finally {
        setLoading(false);
      }
    };
    fetchInterviewData();
  }, [id]);

  const handleStartInterview = async () => {
    setStatus('inProgress');
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      streamRef.current = stream;
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }

      recordedChunksRef.current = [];
      const recorder = new MediaRecorder(stream);
      mediaRecorderRef.current = recorder;

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunksRef.current.push(event.data);
        }
      };

      // --- ğŸ“¹ ë…¹í™” ì¤‘ì§€ ì‹œ ì‹¤í–‰ë  ë¡œì§: ì„œë²„ì— ì—…ë¡œë“œ ---
      recorder.onstop = async () => {
        const videoBlob = new Blob(recordedChunksRef.current, { type: 'video/webm' });
        
        // 1. FormData ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ì˜ìƒ íŒŒì¼ì„ ë‹´ìŠµë‹ˆë‹¤.
        //    ì„œë²„ì˜ @RequestParam("video")ì™€ 'video' í‚¤ ì´ë¦„ì„ ì¼ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
        const formData = new FormData();
        formData.append('video', videoBlob, `interview-${id}.webm`);

        try {
          // 2. ë¨¼ì € /api/upload ì—”ë“œí¬ì¸íŠ¸ë¡œ ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
          //    íŒŒì¼ì„ ë³´ë‚¼ ë•ŒëŠ” Content-Type í—¤ë”ë¥¼ 'multipart/form-data'ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
          alert('ì˜ìƒì„ ì—…ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...');
          const uploadResponse = await apiClient.post('/api/upload', formData, {
            headers: {
              'Content-Type': 'multipart/form-data',
            },
          });
          
          // 3. ì—…ë¡œë“œ ì„±ê³µ ì‹œ, ì„œë²„ë¡œë¶€í„° ë°›ì€ íŒŒì¼ ì´ë¦„ì„ videoUrlë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
          const videoUrl = uploadResponse.data;

          // 4. /api/practice-logs ì—”ë“œí¬ì¸íŠ¸ë¡œ ë©´ì ‘ ê¸°ë¡ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
          const logData = {
            interviewSetId: id, // ì–´ë–¤ ë©´ì ‘ ì„¸íŠ¸ì˜€ëŠ”ì§€
            videoUrl: videoUrl, // ì—…ë¡œë“œëœ ì˜ìƒì˜ íŒŒì¼ëª…
          };
          await apiClient.post('/api/practice-logs', logData);

          alert('ë©´ì ‘ ì˜ìƒì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.');

        } catch (error) {
          console.error('ì˜ìƒ ì—…ë¡œë“œ ë˜ëŠ” ê¸°ë¡ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error);
          alert('ì˜ìƒ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        } finally {
            // ë…¹í™” ë°ì´í„° ì´ˆê¸°í™”
            recordedChunksRef.current = [];
        }
      };

      recorder.start();

    } catch (error) {
      console.error('ì›¹ìº ì„ ì‹œì‘í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error);
      alert('ì›¹ìº /ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      setStatus('ready');
    }
  };

  const handleNextQuestion = () => {
    if (currentQuestionIndex < questions.length - 1) {
      setCurrentQuestionIndex(prevIndex => prevIndex + 1);
    } else {
      handleEndInterview();
    }
  };

  const handleEndInterview = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
      mediaRecorderRef.current.stop();
    }
    setStatus('finished');
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }
  };

  if (loading) return <div>ë©´ì ‘ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...</div>;
  
  if (status === 'ready') {
    return (
      <div>
        <h1>{interviewSet?.name}</h1>
        <p>ë©´ì ‘ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.</p>
        <button onClick={handleStartInterview}>ë©´ì ‘ ì‹œì‘</button>
      </div>
    );
  }

  if (status === 'finished') {
    return (
      <div>
        <h1>ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.</h1>
        <p>ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤. ë©´ì ‘ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
        <button onClick={() => navigate('/interview')}>ë‹¤ë¥¸ ë©´ì ‘ ë³´ëŸ¬ê°€ê¸°</button>
      </div>
    );
  }

  return (
    <div>
      <h1>{interviewSet.name}</h1>
      <hr />
      <video ref={videoRef} autoPlay playsInline muted style={{ width: '400px', border: '1px solid black' }}/>
      <div>
        <h3>ì§ˆë¬¸ {currentQuestionIndex + 1} / {questions.length}</h3>
        <p>{questions.length > 0 ? questions[currentQuestionIndex].content : 'ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.'}</p>
      </div>
      <div>
        <button onClick={handleNextQuestion}>ë‹¤ìŒ ì§ˆë¬¸</button>
        <button onClick={handleEndInterview}>ë©´ì ‘ ì¢…ë£Œ</button>
      </div>
    </div>
  );
}

export default InterviewSessionPage;